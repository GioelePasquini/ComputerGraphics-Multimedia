{"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30699,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"%cd /kaggle/working/\n!GIT_LFS_SKIP_SMUDGE=1 git clone -b dev https://github.com/camenduru/InstantMesh\n%cd /kaggle/working/InstantMesh\n \n!pip install pytorch-lightning==2.1.2 gradio==3.50.2 einops omegaconf torchmetrics webdataset accelerate tensorboard\n!pip install PyMCubes trimesh rembg transformers diffusers==0.20.2 bitsandbytes imageio[ffmpeg] xatlas plyfile\n!pip install git+https://github.com/NVlabs/nvdiffrast jax==0.4.19 jaxlib==0.4.19 ninja\n","metadata":{"id":"VjYy0F2gZIPR","execution":{"iopub.status.busy":"2024-05-30T18:09:43.451265Z","iopub.execute_input":"2024-05-30T18:09:43.451990Z","iopub.status.idle":"2024-05-30T18:11:32.857041Z","shell.execute_reply.started":"2024-05-30T18:09:43.451951Z","shell.execute_reply":"2024-05-30T18:11:32.855999Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"/kaggle/working\nCloning into 'InstantMesh'...\nremote: Enumerating objects: 223, done.\u001b[K\nremote: Counting objects: 100% (65/65), done.\u001b[K\nremote: Compressing objects: 100% (17/17), done.\u001b[K\nremote: Total 223 (delta 56), reused 48 (delta 48), pack-reused 158\u001b[K\nReceiving objects: 100% (223/223), 31.82 MiB | 10.94 MiB/s, done.\nResolving deltas: 100% (78/78), done.\n/kaggle/working/InstantMesh\nCollecting pytorch-lightning==2.1.2\n  Downloading pytorch_lightning-2.1.2-py3-none-any.whl.metadata (21 kB)\nCollecting gradio==3.50.2\n  Downloading gradio-3.50.2-py3-none-any.whl.metadata (17 kB)\nCollecting einops\n  Downloading einops-0.8.0-py3-none-any.whl.metadata (12 kB)\nCollecting omegaconf\n  Downloading omegaconf-2.3.0-py3-none-any.whl.metadata (3.9 kB)\nRequirement already satisfied: torchmetrics in /opt/conda/lib/python3.10/site-packages (1.3.2)\nCollecting webdataset\n  Downloading webdataset-0.2.86-py3-none-any.whl.metadata (29 kB)\nRequirement already satisfied: accelerate in /opt/conda/lib/python3.10/site-packages (0.29.3)\nRequirement already satisfied: tensorboard in /opt/conda/lib/python3.10/site-packages (2.15.1)\nRequirement already satisfied: numpy>=1.17.2 in /opt/conda/lib/python3.10/site-packages (from pytorch-lightning==2.1.2) (1.26.4)\nRequirement already satisfied: torch>=1.12.0 in /opt/conda/lib/python3.10/site-packages (from pytorch-lightning==2.1.2) (2.1.2)\nRequirement already satisfied: tqdm>=4.57.0 in /opt/conda/lib/python3.10/site-packages (from pytorch-lightning==2.1.2) (4.66.1)\nRequirement already satisfied: PyYAML>=5.4 in /opt/conda/lib/python3.10/site-packages (from pytorch-lightning==2.1.2) (6.0.1)\nRequirement already satisfied: fsspec>2021.06.0 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]>2021.06.0->pytorch-lightning==2.1.2) (2024.2.0)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from pytorch-lightning==2.1.2) (21.3)\nRequirement already satisfied: typing-extensions>=4.0.0 in /opt/conda/lib/python3.10/site-packages (from pytorch-lightning==2.1.2) (4.9.0)\nRequirement already satisfied: lightning-utilities>=0.8.0 in /opt/conda/lib/python3.10/site-packages (from pytorch-lightning==2.1.2) (0.11.2)\nRequirement already satisfied: aiofiles<24.0,>=22.0 in /opt/conda/lib/python3.10/site-packages (from gradio==3.50.2) (22.1.0)\nRequirement already satisfied: altair<6.0,>=4.2.0 in /opt/conda/lib/python3.10/site-packages (from gradio==3.50.2) (5.3.0)\nRequirement already satisfied: fastapi in /opt/conda/lib/python3.10/site-packages (from gradio==3.50.2) (0.108.0)\nCollecting ffmpy (from gradio==3.50.2)\n  Downloading ffmpy-0.3.2.tar.gz (5.5 kB)\n  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hCollecting gradio-client==0.6.1 (from gradio==3.50.2)\n  Downloading gradio_client-0.6.1-py3-none-any.whl.metadata (7.1 kB)\nRequirement already satisfied: httpx in /opt/conda/lib/python3.10/site-packages (from gradio==3.50.2) (0.27.0)\nRequirement already satisfied: huggingface-hub>=0.14.0 in /opt/conda/lib/python3.10/site-packages (from gradio==3.50.2) (0.22.2)\nRequirement already satisfied: importlib-resources<7.0,>=1.3 in /opt/conda/lib/python3.10/site-packages (from gradio==3.50.2) (6.1.1)\nRequirement already satisfied: jinja2<4.0 in /opt/conda/lib/python3.10/site-packages (from gradio==3.50.2) (3.1.2)\nRequirement already satisfied: markupsafe~=2.0 in /opt/conda/lib/python3.10/site-packages (from gradio==3.50.2) (2.1.3)\nRequirement already satisfied: matplotlib~=3.0 in /opt/conda/lib/python3.10/site-packages (from gradio==3.50.2) (3.7.5)\nRequirement already satisfied: orjson~=3.0 in /opt/conda/lib/python3.10/site-packages (from gradio==3.50.2) (3.9.10)\nRequirement already satisfied: pandas<3.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from gradio==3.50.2) (2.1.4)\nRequirement already satisfied: pillow<11.0,>=8.0 in /opt/conda/lib/python3.10/site-packages (from gradio==3.50.2) (9.5.0)\nRequirement already satisfied: pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,<3.0.0,>=1.7.4 in /opt/conda/lib/python3.10/site-packages (from gradio==3.50.2) (2.5.3)\nRequirement already satisfied: pydub in /opt/conda/lib/python3.10/site-packages (from gradio==3.50.2) (0.25.1)\nCollecting python-multipart (from gradio==3.50.2)\n  Downloading python_multipart-0.0.9-py3-none-any.whl.metadata (2.5 kB)\nRequirement already satisfied: requests~=2.0 in /opt/conda/lib/python3.10/site-packages (from gradio==3.50.2) (2.31.0)\nCollecting semantic-version~=2.0 (from gradio==3.50.2)\n  Downloading semantic_version-2.10.0-py2.py3-none-any.whl.metadata (9.7 kB)\nRequirement already satisfied: uvicorn>=0.14.0 in /opt/conda/lib/python3.10/site-packages (from gradio==3.50.2) (0.25.0)\nCollecting websockets<12.0,>=10.0 (from gradio==3.50.2)\n  Downloading websockets-11.0.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\nCollecting antlr4-python3-runtime==4.9.* (from omegaconf)\n  Downloading antlr4-python3-runtime-4.9.3.tar.gz (117 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.0/117.0 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hCollecting braceexpand (from webdataset)\n  Downloading braceexpand-0.1.7-py2.py3-none-any.whl.metadata (3.0 kB)\nRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from accelerate) (5.9.3)\nRequirement already satisfied: safetensors>=0.3.1 in /opt/conda/lib/python3.10/site-packages (from accelerate) (0.4.3)\nRequirement already satisfied: absl-py>=0.4 in /opt/conda/lib/python3.10/site-packages (from tensorboard) (1.4.0)\nRequirement already satisfied: grpcio>=1.48.2 in /opt/conda/lib/python3.10/site-packages (from tensorboard) (1.51.1)\nRequirement already satisfied: google-auth<3,>=1.6.3 in /opt/conda/lib/python3.10/site-packages (from tensorboard) (2.26.1)\nRequirement already satisfied: google-auth-oauthlib<2,>=0.5 in /opt/conda/lib/python3.10/site-packages (from tensorboard) (1.2.0)\nRequirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.10/site-packages (from tensorboard) (3.5.2)\nRequirement already satisfied: protobuf<4.24,>=3.19.6 in /opt/conda/lib/python3.10/site-packages (from tensorboard) (3.20.3)\nRequirement already satisfied: setuptools>=41.0.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard) (69.0.3)\nRequirement already satisfied: six>1.9 in /opt/conda/lib/python3.10/site-packages (from tensorboard) (1.16.0)\nRequirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard) (0.7.2)\nRequirement already satisfied: werkzeug>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from tensorboard) (3.0.2)\nRequirement already satisfied: jsonschema>=3.0 in /opt/conda/lib/python3.10/site-packages (from altair<6.0,>=4.2.0->gradio==3.50.2) (4.20.0)\nRequirement already satisfied: toolz in /opt/conda/lib/python3.10/site-packages (from altair<6.0,>=4.2.0->gradio==3.50.2) (0.12.1)\nRequirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]>2021.06.0->pytorch-lightning==2.1.2) (3.9.1)\nRequirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard) (4.2.4)\nRequirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard) (0.3.0)\nRequirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard) (4.9)\nRequirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from google-auth-oauthlib<2,>=0.5->tensorboard) (1.3.1)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.14.0->gradio==3.50.2) (3.13.1)\nRequirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib~=3.0->gradio==3.50.2) (1.2.0)\nRequirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib~=3.0->gradio==3.50.2) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib~=3.0->gradio==3.50.2) (4.47.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib~=3.0->gradio==3.50.2) (1.4.5)\nRequirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib~=3.0->gradio==3.50.2) (3.1.1)\nRequirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.10/site-packages (from matplotlib~=3.0->gradio==3.50.2) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas<3.0,>=1.0->gradio==3.50.2) (2023.3.post1)\nRequirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas<3.0,>=1.0->gradio==3.50.2) (2023.4)\nRequirement already satisfied: annotated-types>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,<3.0.0,>=1.7.4->gradio==3.50.2) (0.6.0)\nRequirement already satisfied: pydantic-core==2.14.6 in /opt/conda/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,<3.0.0,>=1.7.4->gradio==3.50.2) (2.14.6)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests~=2.0->gradio==3.50.2) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests~=2.0->gradio==3.50.2) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests~=2.0->gradio==3.50.2) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests~=2.0->gradio==3.50.2) (2024.2.2)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.12.0->pytorch-lightning==2.1.2) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.12.0->pytorch-lightning==2.1.2) (3.2.1)\nRequirement already satisfied: click>=7.0 in /opt/conda/lib/python3.10/site-packages (from uvicorn>=0.14.0->gradio==3.50.2) (8.1.7)\nRequirement already satisfied: h11>=0.8 in /opt/conda/lib/python3.10/site-packages (from uvicorn>=0.14.0->gradio==3.50.2) (0.14.0)\nRequirement already satisfied: starlette<0.33.0,>=0.29.0 in /opt/conda/lib/python3.10/site-packages (from fastapi->gradio==3.50.2) (0.32.0.post1)\nRequirement already satisfied: anyio in /opt/conda/lib/python3.10/site-packages (from httpx->gradio==3.50.2) (4.2.0)\nRequirement already satisfied: httpcore==1.* in /opt/conda/lib/python3.10/site-packages (from httpx->gradio==3.50.2) (1.0.5)\nRequirement already satisfied: sniffio in /opt/conda/lib/python3.10/site-packages (from httpx->gradio==3.50.2) (1.3.0)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning==2.1.2) (23.2.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning==2.1.2) (6.0.4)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning==2.1.2) (1.9.3)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning==2.1.2) (1.4.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning==2.1.2) (1.3.1)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning==2.1.2) (4.0.3)\nRequirement already satisfied: jsonschema-specifications>=2023.03.6 in /opt/conda/lib/python3.10/site-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio==3.50.2) (2023.12.1)\nRequirement already satisfied: referencing>=0.28.4 in /opt/conda/lib/python3.10/site-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio==3.50.2) (0.32.1)\nRequirement already satisfied: rpds-py>=0.7.1 in /opt/conda/lib/python3.10/site-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio==3.50.2) (0.16.2)\nRequirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /opt/conda/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard) (0.5.1)\nRequirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.10/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard) (3.2.2)\nRequirement already satisfied: exceptiongroup>=1.0.2 in /opt/conda/lib/python3.10/site-packages (from anyio->httpx->gradio==3.50.2) (1.2.0)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.12.0->pytorch-lightning==2.1.2) (1.3.0)\nDownloading pytorch_lightning-2.1.2-py3-none-any.whl (776 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m776.9/776.9 kB\u001b[0m \u001b[31m38.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading gradio-3.50.2-py3-none-any.whl (20.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.3/20.3 MB\u001b[0m \u001b[31m81.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading gradio_client-0.6.1-py3-none-any.whl (299 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m299.2/299.2 kB\u001b[0m \u001b[31m17.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading einops-0.8.0-py3-none-any.whl (43 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.2/43.2 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading omegaconf-2.3.0-py3-none-any.whl (79 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.5/79.5 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading webdataset-0.2.86-py3-none-any.whl (70 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m70.4/70.4 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\nDownloading websockets-11.0.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (129 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.9/129.9 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading braceexpand-0.1.7-py2.py3-none-any.whl (5.9 kB)\nDownloading python_multipart-0.0.9-py3-none-any.whl (22 kB)\nBuilding wheels for collected packages: antlr4-python3-runtime, ffmpy\n  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.9.3-py3-none-any.whl size=144554 sha256=494f84c02e6df15d487210d384c0d6ecc79f8ed6f207bf3768edcbbd6c5eb627\n  Stored in directory: /root/.cache/pip/wheels/12/93/dd/1f6a127edc45659556564c5730f6d4e300888f4bca2d4c5a88\n  Building wheel for ffmpy (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for ffmpy: filename=ffmpy-0.3.2-py3-none-any.whl size=5584 sha256=ac877ab78008443d0bb5e133f8c7598fcea200f4ea91a0fa99cb70a919904867\n  Stored in directory: /root/.cache/pip/wheels/bd/65/9a/671fc6dcde07d4418df0c592f8df512b26d7a0029c2a23dd81\nSuccessfully built antlr4-python3-runtime ffmpy\nInstalling collected packages: ffmpy, braceexpand, antlr4-python3-runtime, websockets, webdataset, semantic-version, python-multipart, omegaconf, einops, gradio-client, pytorch-lightning, gradio\n  Attempting uninstall: websockets\n    Found existing installation: websockets 12.0\n    Uninstalling websockets-12.0:\n      Successfully uninstalled websockets-12.0\n  Attempting uninstall: pytorch-lightning\n    Found existing installation: pytorch-lightning 2.2.2\n    Uninstalling pytorch-lightning-2.2.2:\n      Successfully uninstalled pytorch-lightning-2.2.2\nSuccessfully installed antlr4-python3-runtime-4.9.3 braceexpand-0.1.7 einops-0.8.0 ffmpy-0.3.2 gradio-3.50.2 gradio-client-0.6.1 omegaconf-2.3.0 python-multipart-0.0.9 pytorch-lightning-2.1.2 semantic-version-2.10.0 webdataset-0.2.86 websockets-11.0.3\nCollecting PyMCubes\n  Downloading PyMCubes-0.1.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (863 bytes)\nCollecting trimesh\n  Downloading trimesh-4.4.0-py3-none-any.whl.metadata (18 kB)\nCollecting rembg\n  Downloading rembg-2.0.57-py3-none-any.whl.metadata (16 kB)\nRequirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.39.3)\nCollecting diffusers==0.20.2\n  Downloading diffusers-0.20.2.tar.gz (989 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m989.1/989.1 kB\u001b[0m \u001b[31m30.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n\u001b[?25hCollecting bitsandbytes\n  Downloading bitsandbytes-0.43.1-py3-none-manylinux_2_24_x86_64.whl.metadata (2.2 kB)\nCollecting xatlas\n  Downloading xatlas-0.0.9-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\nCollecting plyfile\n  Downloading plyfile-1.0.3-py3-none-any.whl.metadata (2.1 kB)\nRequirement already satisfied: imageio[ffmpeg] in /opt/conda/lib/python3.10/site-packages (2.33.1)\nRequirement already satisfied: importlib-metadata in /opt/conda/lib/python3.10/site-packages (from diffusers==0.20.2) (6.11.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from diffusers==0.20.2) (3.13.1)\nRequirement already satisfied: huggingface-hub>=0.13.2 in /opt/conda/lib/python3.10/site-packages (from diffusers==0.20.2) (0.22.2)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from diffusers==0.20.2) (1.26.4)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from diffusers==0.20.2) (2023.12.25)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from diffusers==0.20.2) (2.31.0)\nRequirement already satisfied: safetensors>=0.3.1 in /opt/conda/lib/python3.10/site-packages (from diffusers==0.20.2) (0.4.3)\nRequirement already satisfied: Pillow in /opt/conda/lib/python3.10/site-packages (from diffusers==0.20.2) (9.5.0)\nRequirement already satisfied: scipy>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from PyMCubes) (1.11.4)\nRequirement already satisfied: jsonschema in /opt/conda/lib/python3.10/site-packages (from rembg) (4.20.0)\nCollecting onnxruntime (from rembg)\n  Downloading onnxruntime-1.18.0-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (4.3 kB)\nRequirement already satisfied: opencv-python-headless in /opt/conda/lib/python3.10/site-packages (from rembg) (4.9.0.80)\nRequirement already satisfied: pooch in /opt/conda/lib/python3.10/site-packages (from rembg) (1.8.1)\nCollecting pymatting (from rembg)\n  Downloading PyMatting-1.1.12-py3-none-any.whl.metadata (7.4 kB)\nRequirement already satisfied: scikit-image in /opt/conda/lib/python3.10/site-packages (from rembg) (0.22.0)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from rembg) (4.66.1)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (6.0.1)\nRequirement already satisfied: tokenizers<0.19,>=0.14 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.15.2)\nRequirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (from bitsandbytes) (2.1.2)\nCollecting imageio-ffmpeg (from imageio[ffmpeg])\n  Downloading imageio_ffmpeg-0.4.9-py3-none-manylinux2010_x86_64.whl.metadata (1.7 kB)\nRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from imageio[ffmpeg]) (5.9.3)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.13.2->diffusers==0.20.2) (2024.2.0)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.13.2->diffusers==0.20.2) (4.9.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers) (3.1.1)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from imageio-ffmpeg->imageio[ffmpeg]) (69.0.3)\nRequirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.10/site-packages (from importlib-metadata->diffusers==0.20.2) (3.17.0)\nRequirement already satisfied: attrs>=22.2.0 in /opt/conda/lib/python3.10/site-packages (from jsonschema->rembg) (23.2.0)\nRequirement already satisfied: jsonschema-specifications>=2023.03.6 in /opt/conda/lib/python3.10/site-packages (from jsonschema->rembg) (2023.12.1)\nRequirement already satisfied: referencing>=0.28.4 in /opt/conda/lib/python3.10/site-packages (from jsonschema->rembg) (0.32.1)\nRequirement already satisfied: rpds-py>=0.7.1 in /opt/conda/lib/python3.10/site-packages (from jsonschema->rembg) (0.16.2)\nCollecting coloredlogs (from onnxruntime->rembg)\n  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\nRequirement already satisfied: flatbuffers in /opt/conda/lib/python3.10/site-packages (from onnxruntime->rembg) (23.5.26)\nRequirement already satisfied: protobuf in /opt/conda/lib/python3.10/site-packages (from onnxruntime->rembg) (3.20.3)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from onnxruntime->rembg) (1.12)\nRequirement already satisfied: platformdirs>=2.5.0 in /opt/conda/lib/python3.10/site-packages (from pooch->rembg) (4.2.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->diffusers==0.20.2) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->diffusers==0.20.2) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->diffusers==0.20.2) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->diffusers==0.20.2) (2024.2.2)\nRequirement already satisfied: numba!=0.49.0 in /opt/conda/lib/python3.10/site-packages (from pymatting->rembg) (0.58.1)\nRequirement already satisfied: networkx>=2.8 in /opt/conda/lib/python3.10/site-packages (from scikit-image->rembg) (3.2.1)\nRequirement already satisfied: tifffile>=2022.8.12 in /opt/conda/lib/python3.10/site-packages (from scikit-image->rembg) (2023.12.9)\nRequirement already satisfied: lazy_loader>=0.3 in /opt/conda/lib/python3.10/site-packages (from scikit-image->rembg) (0.3)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (3.1.2)\nRequirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in /opt/conda/lib/python3.10/site-packages (from numba!=0.49.0->pymatting->rembg) (0.41.1)\nCollecting humanfriendly>=9.1 (from coloredlogs->onnxruntime->rembg)\n  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch->bitsandbytes) (2.1.3)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->onnxruntime->rembg) (1.3.0)\nDownloading PyMCubes-0.1.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (274 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m274.3/274.3 kB\u001b[0m \u001b[31m17.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading trimesh-4.4.0-py3-none-any.whl (694 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m694.6/694.6 kB\u001b[0m \u001b[31m32.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading rembg-2.0.57-py3-none-any.whl (33 kB)\nDownloading bitsandbytes-0.43.1-py3-none-manylinux_2_24_x86_64.whl (119.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m119.8/119.8 MB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading xatlas-0.0.9-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (230 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m230.1/230.1 kB\u001b[0m \u001b[31m16.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading plyfile-1.0.3-py3-none-any.whl (23 kB)\nDownloading imageio_ffmpeg-0.4.9-py3-none-manylinux2010_x86_64.whl (26.9 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m26.9/26.9 MB\u001b[0m \u001b[31m62.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading onnxruntime-1.18.0-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (6.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.8/6.8 MB\u001b[0m \u001b[31m92.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading PyMatting-1.1.12-py3-none-any.whl (52 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.0/53.0 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hBuilding wheels for collected packages: diffusers\n  Building wheel for diffusers (pyproject.toml) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for diffusers: filename=diffusers-0.20.2-py3-none-any.whl size=1342633 sha256=caabf4d90694455ca3c8cbdaf4fae2459d8a28dbcf20cf3a4967dc4ed5761dde\n  Stored in directory: /root/.cache/pip/wheels/dc/8b/d9/34f7a1936109e05e9bba0cc2241a6f8cd89e25959dc7aae942\nSuccessfully built diffusers\nInstalling collected packages: xatlas, trimesh, plyfile, imageio-ffmpeg, humanfriendly, PyMCubes, pymatting, coloredlogs, onnxruntime, diffusers, bitsandbytes, rembg\nSuccessfully installed PyMCubes-0.1.4 bitsandbytes-0.43.1 coloredlogs-15.0.1 diffusers-0.20.2 humanfriendly-10.0 imageio-ffmpeg-0.4.9 onnxruntime-1.18.0 plyfile-1.0.3 pymatting-1.1.12 rembg-2.0.57 trimesh-4.4.0 xatlas-0.0.9\nCollecting git+https://github.com/NVlabs/nvdiffrast\n  Cloning https://github.com/NVlabs/nvdiffrast to /tmp/pip-req-build-m7cuqeno\n  Running command git clone --filter=blob:none --quiet https://github.com/NVlabs/nvdiffrast /tmp/pip-req-build-m7cuqeno\n  Resolved https://github.com/NVlabs/nvdiffrast to commit c5caf7bdb8a2448acc491a9faa47753972edd380\n  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hCollecting jax==0.4.19\n  Downloading jax-0.4.19-py3-none-any.whl.metadata (23 kB)\nCollecting jaxlib==0.4.19\n  Downloading jaxlib-0.4.19-cp310-cp310-manylinux2014_x86_64.whl.metadata (2.1 kB)\nRequirement already satisfied: ninja in /opt/conda/lib/python3.10/site-packages (1.11.1.1)\nRequirement already satisfied: ml-dtypes>=0.2.0 in /opt/conda/lib/python3.10/site-packages (from jax==0.4.19) (0.2.0)\nRequirement already satisfied: numpy>=1.22 in /opt/conda/lib/python3.10/site-packages (from jax==0.4.19) (1.26.4)\nRequirement already satisfied: opt-einsum in /opt/conda/lib/python3.10/site-packages (from jax==0.4.19) (3.3.0)\nRequirement already satisfied: scipy>=1.9 in /opt/conda/lib/python3.10/site-packages (from jax==0.4.19) (1.11.4)\nDownloading jax-0.4.19-py3-none-any.whl (1.7 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m45.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading jaxlib-0.4.19-cp310-cp310-manylinux2014_x86_64.whl (85.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.3/85.3 MB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n\u001b[?25hBuilding wheels for collected packages: nvdiffrast\n  Building wheel for nvdiffrast (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for nvdiffrast: filename=nvdiffrast-0.3.1-py3-none-any.whl size=140616 sha256=6cd03239b992d00ae8ded351cc1e8b494e82f5a3d27dc84b4fa0c1c8f5aad250\n  Stored in directory: /tmp/pip-ephem-wheel-cache-k83dexit/wheels/11/96/d0/82457e00d4e4930e20309b0af252ee695ce1aee8bb37bc7258\nSuccessfully built nvdiffrast\nInstalling collected packages: nvdiffrast, jaxlib, jax\n  Attempting uninstall: jaxlib\n    Found existing installation: jaxlib 0.4.23.dev20240116\n    Uninstalling jaxlib-0.4.23.dev20240116:\n      Successfully uninstalled jaxlib-0.4.23.dev20240116\n  Attempting uninstall: jax\n    Found existing installation: jax 0.4.23\n    Uninstalling jax-0.4.23:\n      Successfully uninstalled jax-0.4.23\nSuccessfully installed jax-0.4.19 jaxlib-0.4.19 nvdiffrast-0.3.1\n","output_type":"stream"}]},{"cell_type":"code","source":"!python run.py configs/instant-mesh-base.yaml examples/pikachu.png --export_texmap","metadata":{"execution":{"iopub.status.busy":"2024-05-30T18:12:43.776602Z","iopub.execute_input":"2024-05-30T18:12:43.776992Z","iopub.status.idle":"2024-05-30T18:18:26.902501Z","shell.execute_reply.started":"2024-05-30T18:12:43.776958Z","shell.execute_reply":"2024-05-30T18:18:26.901423Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"2024-05-30 18:13:36.656249: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-05-30 18:13:36.656370: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-05-30 18:13:36.761103: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\nLoading diffusion model ...\nmodel_index.json: 100%|████████████████████| 2.63k/2.63k [00:00<00:00, 11.2MB/s]\nFetching 16 files:   0%|                                 | 0/16 [00:00<?, ?it/s]\n(…)_extractor_clip/preprocessor_config.json: 100%|█| 466/466 [00:00<00:00, 2.06M\u001b[A\nFetching 16 files:   6%|█▌                       | 1/16 [00:00<00:06,  2.15it/s]\n(…)e_extractor_vae/preprocessor_config.json: 100%|█| 369/369 [00:00<00:00, 2.31M\u001b[A\n\nscheduler/scheduler_config.json: 100%|█████████| 391/391 [00:00<00:00, 2.84MB/s]\u001b[A\n\ntokenizer/special_tokens_map.json: 100%|███████| 460/460 [00:00<00:00, 3.01MB/s]\u001b[A\n\ntokenizer/merges.txt: 100%|██████████████████| 525k/525k [00:00<00:00, 33.2MB/s]\u001b[A\n\ntokenizer/tokenizer_config.json: 100%|█████████| 855/855 [00:00<00:00, 5.95MB/s]\u001b[A\n\ntext_encoder/model.safetensors:   0%|                | 0.00/681M [00:00<?, ?B/s]\u001b[A\n\ntext_encoder/config.json: 100%|████████████████| 708/708 [00:00<00:00, 2.57MB/s]\u001b[A\u001b[A\n\n\nunet/config.json: 100%|████████████████████| 1.96k/1.96k [00:00<00:00, 8.88MB/s]\u001b[A\u001b[A\n\n\ntokenizer/vocab.json:   0%|                         | 0.00/1.06M [00:00<?, ?B/s]\u001b[A\u001b[A\n\n\nvae/config.json: 100%|█████████████████████████| 745/745 [00:00<00:00, 3.91MB/s]\u001b[A\u001b[A\u001b[A\n\n\n\nunet/diffusion_pytorch_model.safetensors:   0%|     | 0.00/3.46G [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\n\n\n\nvision_encoder/config.json: 100%|██████████████| 672/672 [00:00<00:00, 3.73MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\nvae/diffusion_pytorch_model.safetensors:   0%|       | 0.00/167M [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\nvision_encoder/model.safetensors:   0%|             | 0.00/1.26G [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\nunet/diffusion_pytorch_model.safetensors:   1%| | 31.5M/3.46G [00:00<00:12, 267M\u001b[A\u001b[A\u001b[A\n\ntokenizer/vocab.json: 100%|████████████████| 1.06M/1.06M [00:00<00:00, 5.19MB/s]\u001b[A\u001b[A\n\n\n\nunet/diffusion_pytorch_model.safetensors:   2%| | 83.9M/3.46G [00:00<00:09, 362M\u001b[A\u001b[A\u001b[A\n\n\nunet/diffusion_pytorch_model.safetensors:   4%| | 136M/3.46G [00:00<00:08, 399MB\u001b[A\u001b[A\u001b[A\n\n\n\nvae/diffusion_pytorch_model.safetensors:   6%| | 10.5M/167M [00:00<00:06, 25.9MB\u001b[A\u001b[A\u001b[A\u001b[A\n\n\nunet/diffusion_pytorch_model.safetensors:   5%| | 189M/3.46G [00:00<00:07, 415MB\u001b[A\u001b[A\u001b[A\n\n\n\n\nvision_encoder/model.safetensors:   1%|    | 10.5M/1.26G [00:00<00:49, 25.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\nunet/diffusion_pytorch_model.safetensors:   7%| | 241M/3.46G [00:00<00:07, 429MB\u001b[A\u001b[A\u001b[A\n\n\nunet/diffusion_pytorch_model.safetensors:   8%| | 294M/3.46G [00:00<00:07, 442MB\u001b[A\u001b[A\u001b[A\ntext_encoder/model.safetensors:   2%|       | 10.5M/681M [00:01<01:17, 8.69MB/s]\u001b[A\n\n\nunet/diffusion_pytorch_model.safetensors:  10%| | 346M/3.46G [00:00<00:07, 440MB\u001b[A\u001b[A\u001b[A\n\n\n\nvae/diffusion_pytorch_model.safetensors:  13%|▏| 21.0M/167M [00:00<00:05, 26.3MB\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\nvision_encoder/model.safetensors:   2%|    | 21.0M/1.26G [00:00<00:47, 26.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\nunet/diffusion_pytorch_model.safetensors:  12%| | 398M/3.46G [00:00<00:07, 428MB\u001b[A\u001b[A\u001b[A\n\n\nunet/diffusion_pytorch_model.safetensors:  13%|▏| 451M/3.46G [00:01<00:06, 433MB\u001b[A\u001b[A\u001b[A\ntext_encoder/model.safetensors:   3%|▏      | 21.0M/681M [00:01<00:45, 14.4MB/s]\u001b[A\n\n\nunet/diffusion_pytorch_model.safetensors:  15%|▏| 503M/3.46G [00:01<00:06, 443MB\u001b[A\u001b[A\u001b[A\n\n\n\nvae/diffusion_pytorch_model.safetensors:  19%|▏| 31.5M/167M [00:01<00:05, 26.6MB\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\nvision_encoder/model.safetensors:   2%|    | 31.5M/1.26G [00:01<00:46, 26.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\nunet/diffusion_pytorch_model.safetensors:  16%|▏| 556M/3.46G [00:01<00:06, 448MB\u001b[A\u001b[A\u001b[A\n\n\nunet/diffusion_pytorch_model.safetensors:  18%|▏| 608M/3.46G [00:01<00:06, 461MB\u001b[A\u001b[A\u001b[A\n\n\nunet/diffusion_pytorch_model.safetensors:  19%|▏| 661M/3.46G [00:01<00:06, 462MB\u001b[A\u001b[A\u001b[A\ntext_encoder/model.safetensors:   5%|▎      | 31.5M/681M [00:01<00:35, 18.2MB/s]\u001b[A\n\n\n\nvae/diffusion_pytorch_model.safetensors:  25%|▎| 41.9M/167M [00:01<00:04, 26.6MB\u001b[A\u001b[A\u001b[A\u001b[A\n\n\nunet/diffusion_pytorch_model.safetensors:  21%|▏| 713M/3.46G [00:01<00:06, 450MB\u001b[A\u001b[A\u001b[A\n\n\n\n\nvision_encoder/model.safetensors:   3%|▏   | 41.9M/1.26G [00:01<00:45, 26.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\nunet/diffusion_pytorch_model.safetensors:  22%|▏| 765M/3.46G [00:01<00:05, 450MB\u001b[A\u001b[A\u001b[A\n\n\nunet/diffusion_pytorch_model.safetensors:  24%|▏| 818M/3.46G [00:01<00:05, 452MB\u001b[A\u001b[A\u001b[A\ntext_encoder/model.safetensors:   6%|▍      | 41.9M/681M [00:02<00:30, 20.8MB/s]\u001b[A\n\n\nunet/diffusion_pytorch_model.safetensors:  25%|▎| 870M/3.46G [00:01<00:05, 449MB\u001b[A\u001b[A\u001b[A\n\n\n\nvae/diffusion_pytorch_model.safetensors:  31%|▎| 52.4M/167M [00:01<00:04, 26.6MB\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\nvision_encoder/model.safetensors:   4%|▏   | 52.4M/1.26G [00:01<00:45, 26.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\nunet/diffusion_pytorch_model.safetensors:  27%|▎| 923M/3.46G [00:02<00:05, 443MB\u001b[A\u001b[A\u001b[A\n\n\nunet/diffusion_pytorch_model.safetensors:  28%|▎| 975M/3.46G [00:02<00:05, 445MB\u001b[A\u001b[A\u001b[A\n\n\nunet/diffusion_pytorch_model.safetensors:  30%|▎| 1.03G/3.46G [00:02<00:05, 454M\u001b[A\u001b[A\u001b[A\ntext_encoder/model.safetensors:   8%|▌      | 52.4M/681M [00:02<00:27, 22.5MB/s]\u001b[A\n\n\n\nvae/diffusion_pytorch_model.safetensors:  38%|▍| 62.9M/167M [00:02<00:03, 26.6MB\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\nvision_encoder/model.safetensors:   5%|▏   | 62.9M/1.26G [00:02<00:44, 26.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\nunet/diffusion_pytorch_model.safetensors:  31%|▎| 1.08G/3.46G [00:02<00:05, 442M\u001b[A\u001b[A\u001b[A\n\n\nunet/diffusion_pytorch_model.safetensors:  33%|▎| 1.13G/3.46G [00:02<00:05, 451M\u001b[A\u001b[A\u001b[A\n\n\nunet/diffusion_pytorch_model.safetensors:  34%|▎| 1.18G/3.46G [00:02<00:05, 451M\u001b[A\u001b[A\u001b[A\ntext_encoder/model.safetensors:   9%|▋      | 62.9M/681M [00:03<00:26, 23.7MB/s]\u001b[A\n\n\nunet/diffusion_pytorch_model.safetensors:  36%|▎| 1.24G/3.46G [00:02<00:04, 456M\u001b[A\u001b[A\u001b[A\n\n\n\nvae/diffusion_pytorch_model.safetensors:  44%|▍| 73.4M/167M [00:02<00:03, 26.6MB\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\nvision_encoder/model.safetensors:   6%|▏   | 73.4M/1.26G [00:02<00:44, 26.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\nunet/diffusion_pytorch_model.safetensors:  37%|▎| 1.29G/3.46G [00:02<00:04, 457M\u001b[A\u001b[A\u001b[A\n\n\nunet/diffusion_pytorch_model.safetensors:  39%|▍| 1.34G/3.46G [00:03<00:04, 456M\u001b[A\u001b[A\u001b[A\n\n\nunet/diffusion_pytorch_model.safetensors:  40%|▍| 1.39G/3.46G [00:03<00:04, 467M\u001b[A\u001b[A\u001b[A\ntext_encoder/model.safetensors:  11%|▊      | 73.4M/681M [00:03<00:24, 24.5MB/s]\u001b[A\n\n\n\nvae/diffusion_pytorch_model.safetensors:  50%|▌| 83.9M/167M [00:03<00:03, 26.6MB\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\nvision_encoder/model.safetensors:   7%|▎   | 83.9M/1.26G [00:03<00:44, 26.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\nunet/diffusion_pytorch_model.safetensors:  42%|▍| 1.45G/3.46G [00:03<00:04, 445M\u001b[A\u001b[A\u001b[A\n\n\nunet/diffusion_pytorch_model.safetensors:  43%|▍| 1.50G/3.46G [00:03<00:04, 440M\u001b[A\u001b[A\u001b[A\n\n\nunet/diffusion_pytorch_model.safetensors:  45%|▍| 1.55G/3.46G [00:03<00:04, 437M\u001b[A\u001b[A\u001b[A\ntext_encoder/model.safetensors:  12%|▊      | 83.9M/681M [00:03<00:23, 25.1MB/s]\u001b[A\n\n\n\nvae/diffusion_pytorch_model.safetensors:  56%|▌| 94.4M/167M [00:03<00:02, 26.6MB\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\nvision_encoder/model.safetensors:   7%|▎   | 94.4M/1.26G [00:03<00:43, 26.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\nunet/diffusion_pytorch_model.safetensors:  46%|▍| 1.60G/3.46G [00:03<00:04, 434M\u001b[A\u001b[A\u001b[A\n\n\nunet/diffusion_pytorch_model.safetensors:  48%|▍| 1.66G/3.46G [00:03<00:04, 451M\u001b[A\u001b[A\u001b[A\n\n\nunet/diffusion_pytorch_model.safetensors:  49%|▍| 1.71G/3.46G [00:03<00:03, 453M\u001b[A\u001b[A\u001b[A\ntext_encoder/model.safetensors:  14%|▉      | 94.4M/681M [00:04<00:23, 25.4MB/s]\u001b[A\n\n\nunet/diffusion_pytorch_model.safetensors:  51%|▌| 1.76G/3.46G [00:03<00:03, 461M\u001b[A\u001b[A\u001b[A\n\n\n\nvae/diffusion_pytorch_model.safetensors:  63%|▋| 105M/167M [00:03<00:02, 26.5MB/\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\nvision_encoder/model.safetensors:   8%|▍    | 105M/1.26G [00:03<00:43, 26.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\nunet/diffusion_pytorch_model.safetensors:  52%|▌| 1.81G/3.46G [00:04<00:03, 443M\u001b[A\u001b[A\u001b[A\n\n\nunet/diffusion_pytorch_model.safetensors:  54%|▌| 1.87G/3.46G [00:04<00:03, 445M\u001b[A\u001b[A\u001b[A\n\n\nunet/diffusion_pytorch_model.safetensors:  55%|▌| 1.92G/3.46G [00:04<00:03, 462M\u001b[A\u001b[A\u001b[A\ntext_encoder/model.safetensors:  15%|█▏      | 105M/681M [00:04<00:22, 25.7MB/s]\u001b[A\n\n\n\nvae/diffusion_pytorch_model.safetensors:  69%|▋| 115M/167M [00:04<00:01, 26.6MB/\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\nvision_encoder/model.safetensors:   9%|▍    | 115M/1.26G [00:04<00:43, 26.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\nunet/diffusion_pytorch_model.safetensors:  57%|▌| 1.97G/3.46G [00:04<00:03, 446M\u001b[A\u001b[A\u001b[A\n\n\nunet/diffusion_pytorch_model.safetensors:  58%|▌| 2.02G/3.46G [00:04<00:03, 459M\u001b[A\u001b[A\u001b[A\n\n\nunet/diffusion_pytorch_model.safetensors:  60%|▌| 2.08G/3.46G [00:04<00:03, 460M\u001b[A\u001b[A\u001b[A\ntext_encoder/model.safetensors:  17%|█▎      | 115M/681M [00:05<00:21, 25.9MB/s]\u001b[A\n\n\nunet/diffusion_pytorch_model.safetensors:  61%|▌| 2.13G/3.46G [00:04<00:02, 461M\u001b[A\u001b[A\u001b[A\n\n\n\nvae/diffusion_pytorch_model.safetensors:  75%|▊| 126M/167M [00:04<00:01, 26.6MB/\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\nvision_encoder/model.safetensors:  10%|▍    | 126M/1.26G [00:04<00:42, 26.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\nunet/diffusion_pytorch_model.safetensors:  63%|▋| 2.18G/3.46G [00:04<00:02, 451M\u001b[A\u001b[A\u001b[A\n\n\nunet/diffusion_pytorch_model.safetensors:  64%|▋| 2.23G/3.46G [00:05<00:02, 448M\u001b[A\u001b[A\u001b[A\n\n\nunet/diffusion_pytorch_model.safetensors:  66%|▋| 2.29G/3.46G [00:05<00:02, 459M\u001b[A\u001b[A\u001b[A\ntext_encoder/model.safetensors:  18%|█▍      | 126M/681M [00:05<00:21, 26.0MB/s]\u001b[A\n\n\n\nvae/diffusion_pytorch_model.safetensors:  81%|▊| 136M/167M [00:05<00:01, 26.6MB/\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\nvision_encoder/model.safetensors:  11%|▌    | 136M/1.26G [00:05<00:42, 26.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\nunet/diffusion_pytorch_model.safetensors:  68%|▋| 2.34G/3.46G [00:05<00:02, 439M\u001b[A\u001b[A\u001b[A\n\n\nunet/diffusion_pytorch_model.safetensors:  69%|▋| 2.39G/3.46G [00:05<00:02, 391M\u001b[A\u001b[A\u001b[A\ntext_encoder/model.safetensors:  20%|█▌      | 136M/681M [00:05<00:20, 26.1MB/s]\u001b[A\n\n\nunet/diffusion_pytorch_model.safetensors:  70%|▋| 2.43G/3.46G [00:05<00:02, 381M\u001b[A\u001b[A\u001b[A\n\n\n\nvae/diffusion_pytorch_model.safetensors:  88%|▉| 147M/167M [00:05<00:00, 26.6MB/\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\nvision_encoder/model.safetensors:  12%|▌    | 147M/1.26G [00:05<00:41, 26.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\nunet/diffusion_pytorch_model.safetensors:  71%|▋| 2.47G/3.46G [00:05<00:02, 372M\u001b[A\u001b[A\u001b[A\n\n\nunet/diffusion_pytorch_model.safetensors:  73%|▋| 2.53G/3.46G [00:05<00:02, 381M\u001b[A\u001b[A\u001b[A\n\n\nunet/diffusion_pytorch_model.safetensors:  74%|▋| 2.58G/3.46G [00:05<00:02, 410M\u001b[A\u001b[A\u001b[A\ntext_encoder/model.safetensors:  22%|█▋      | 147M/681M [00:06<00:20, 26.2MB/s]\u001b[A\n\n\n\nvae/diffusion_pytorch_model.safetensors:  94%|▉| 157M/167M [00:05<00:00, 26.5MB/\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\nvision_encoder/model.safetensors:  12%|▌    | 157M/1.26G [00:05<00:41, 26.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\nunet/diffusion_pytorch_model.safetensors:  76%|▊| 2.62G/3.46G [00:06<00:02, 377M\u001b[A\u001b[A\u001b[A\n\n\nunet/diffusion_pytorch_model.safetensors:  77%|▊| 2.66G/3.46G [00:06<00:02, 344M\u001b[A\u001b[A\u001b[A\n\n\nunet/diffusion_pytorch_model.safetensors:  78%|▊| 2.71G/3.46G [00:06<00:02, 333M\u001b[A\u001b[A\u001b[A\ntext_encoder/model.safetensors:  23%|█▊      | 157M/681M [00:06<00:20, 26.2MB/s]\u001b[A\n\n\n\nvae/diffusion_pytorch_model.safetensors: 100%|█| 167M/167M [00:06<00:00, 26.4MB/\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\nvision_encoder/model.safetensors:  13%|▋    | 168M/1.26G [00:06<00:41, 26.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\nunet/diffusion_pytorch_model.safetensors:  79%|▊| 2.75G/3.46G [00:06<00:02, 305M\u001b[A\u001b[A\u001b[A\n\n\nunet/diffusion_pytorch_model.safetensors:  81%|▊| 2.79G/3.46G [00:06<00:02, 312M\u001b[A\u001b[A\u001b[A\ntext_encoder/model.safetensors:  25%|█▉      | 168M/681M [00:07<00:19, 26.3MB/s]\u001b[A\n\n\nunet/diffusion_pytorch_model.safetensors:  82%|▊| 2.83G/3.46G [00:06<00:02, 315M\u001b[A\u001b[A\u001b[A\n\n\n\n\nvision_encoder/model.safetensors:  14%|▋    | 178M/1.26G [00:06<00:40, 26.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\nunet/diffusion_pytorch_model.safetensors:  83%|▊| 2.87G/3.46G [00:06<00:01, 314M\u001b[A\u001b[A\u001b[A\n\n\nunet/diffusion_pytorch_model.safetensors:  84%|▊| 2.92G/3.46G [00:07<00:01, 321M\u001b[A\u001b[A\u001b[A\n\n\nunet/diffusion_pytorch_model.safetensors:  85%|▊| 2.96G/3.46G [00:07<00:01, 337M\u001b[A\u001b[A\u001b[A\ntext_encoder/model.safetensors:  26%|██      | 178M/681M [00:07<00:19, 26.4MB/s]\u001b[A\n\n\n\n\nvision_encoder/model.safetensors:  15%|▋    | 189M/1.26G [00:07<00:40, 26.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\nunet/diffusion_pytorch_model.safetensors:  87%|▊| 3.00G/3.46G [00:07<00:01, 341M\u001b[A\u001b[A\u001b[A\n\n\nunet/diffusion_pytorch_model.safetensors:  88%|▉| 3.04G/3.46G [00:07<00:01, 357M\u001b[A\u001b[A\u001b[A\n\n\nunet/diffusion_pytorch_model.safetensors:  89%|▉| 3.09G/3.46G [00:07<00:00, 379M\u001b[A\u001b[A\u001b[A\ntext_encoder/model.safetensors:  28%|██▏     | 189M/681M [00:07<00:18, 26.3MB/s]\u001b[A\n\n\n\n\nvision_encoder/model.safetensors:  16%|▊    | 199M/1.26G [00:07<00:39, 26.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\nunet/diffusion_pytorch_model.safetensors:  91%|▉| 3.14G/3.46G [00:07<00:00, 367M\u001b[A\u001b[A\u001b[A\n\n\nunet/diffusion_pytorch_model.safetensors:  92%|▉| 3.19G/3.46G [00:07<00:00, 385M\u001b[A\u001b[A\u001b[A\n\n\nunet/diffusion_pytorch_model.safetensors:  93%|▉| 3.23G/3.46G [00:07<00:00, 388M\u001b[A\u001b[A\u001b[A\ntext_encoder/model.safetensors:  29%|██▎     | 199M/681M [00:08<00:18, 26.3MB/s]\u001b[A\n\n\nunet/diffusion_pytorch_model.safetensors:  95%|▉| 3.28G/3.46G [00:07<00:00, 395M\u001b[A\u001b[A\u001b[A\n\n\n\n\nvision_encoder/model.safetensors:  17%|▊    | 210M/1.26G [00:07<00:39, 26.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\nunet/diffusion_pytorch_model.safetensors:  96%|▉| 3.32G/3.46G [00:08<00:00, 385M\u001b[A\u001b[A\u001b[A\n\n\nunet/diffusion_pytorch_model.safetensors:  97%|▉| 3.37G/3.46G [00:08<00:00, 367M\u001b[A\u001b[A\u001b[A\n\n\nunet/diffusion_pytorch_model.safetensors:  98%|▉| 3.41G/3.46G [00:08<00:00, 369M\u001b[A\u001b[A\u001b[A\ntext_encoder/model.safetensors:  31%|██▍     | 210M/681M [00:08<00:17, 26.3MB/s]\u001b[A\n\n\nunet/diffusion_pytorch_model.safetensors: 100%|█| 3.46G/3.46G [00:08<00:00, 410M\u001b[A\u001b[A\u001b[A\n\n\n\n\n\nvision_encoder/model.safetensors:  17%|▊    | 220M/1.26G [00:08<00:44, 23.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\ntext_encoder/model.safetensors:  32%|██▌     | 220M/681M [00:09<00:17, 26.4MB/s]\u001b[A\n\n\n\n\nvision_encoder/model.safetensors:  18%|▉    | 231M/1.26G [00:08<00:42, 24.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\ntext_encoder/model.safetensors:  34%|██▋     | 231M/681M [00:09<00:17, 26.4MB/s]\u001b[A\n\n\n\n\nvision_encoder/model.safetensors:  19%|▉    | 241M/1.26G [00:09<00:41, 24.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\ntext_encoder/model.safetensors:  35%|██▊     | 241M/681M [00:09<00:16, 26.4MB/s]\u001b[A\n\n\n\n\nvision_encoder/model.safetensors:  20%|▉    | 252M/1.26G [00:09<00:39, 25.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\ntext_encoder/model.safetensors:  37%|██▉     | 252M/681M [00:10<00:16, 25.5MB/s]\u001b[A\n\n\n\n\nvision_encoder/model.safetensors:  21%|█    | 262M/1.26G [00:10<00:38, 25.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\ntext_encoder/model.safetensors:  39%|███     | 262M/681M [00:10<00:15, 26.6MB/s]\u001b[A\n\n\n\n\nvision_encoder/model.safetensors:  22%|█    | 273M/1.26G [00:10<00:38, 26.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\ntext_encoder/model.safetensors:  40%|███▏    | 273M/681M [00:11<00:15, 26.5MB/s]\u001b[A\n\n\n\n\nvision_encoder/model.safetensors:  22%|█    | 283M/1.26G [00:10<00:37, 26.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\ntext_encoder/model.safetensors:  42%|███▎    | 283M/681M [00:11<00:15, 26.5MB/s]\u001b[A\n\n\n\n\nvision_encoder/model.safetensors:  23%|█▏   | 294M/1.26G [00:11<00:36, 26.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\ntext_encoder/model.safetensors:  43%|███▍    | 294M/681M [00:11<00:14, 26.5MB/s]\u001b[A\n\n\n\n\nvision_encoder/model.safetensors:  24%|█▏   | 304M/1.26G [00:11<00:36, 26.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\ntext_encoder/model.safetensors:  45%|███▌    | 304M/681M [00:12<00:14, 26.2MB/s]\u001b[A\n\n\n\n\nvision_encoder/model.safetensors:  25%|█▏   | 315M/1.26G [00:11<00:35, 26.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\ntext_encoder/model.safetensors:  46%|███▋    | 315M/681M [00:12<00:13, 26.2MB/s]\u001b[A\n\n\n\n\nvision_encoder/model.safetensors:  26%|█▎   | 325M/1.26G [00:12<00:35, 26.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\ntext_encoder/model.safetensors:  48%|███▊    | 325M/681M [00:13<00:13, 26.2MB/s]\u001b[A\n\n\n\n\nvision_encoder/model.safetensors:  27%|█▎   | 336M/1.26G [00:12<00:35, 26.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\ntext_encoder/model.safetensors:  49%|███▉    | 336M/681M [00:13<00:13, 26.3MB/s]\u001b[A\n\n\n\n\nvision_encoder/model.safetensors:  27%|█▎   | 346M/1.26G [00:13<00:34, 26.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\ntext_encoder/model.safetensors:  51%|████    | 346M/681M [00:13<00:12, 26.3MB/s]\u001b[A\n\n\n\n\nvision_encoder/model.safetensors:  28%|█▍   | 357M/1.26G [00:13<00:34, 26.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\ntext_encoder/model.safetensors:  52%|████▏   | 357M/681M [00:14<00:12, 26.3MB/s]\u001b[A\n\n\n\n\nvision_encoder/model.safetensors:  29%|█▍   | 367M/1.26G [00:13<00:33, 26.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\ntext_encoder/model.safetensors:  54%|████▎   | 367M/681M [00:14<00:11, 26.3MB/s]\u001b[A\n\n\n\n\nvision_encoder/model.safetensors:  30%|█▍   | 377M/1.26G [00:14<00:33, 26.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\ntext_encoder/model.safetensors:  55%|████▍   | 377M/681M [00:15<00:11, 26.3MB/s]\u001b[A\n\n\n\n\nvision_encoder/model.safetensors:  31%|█▌   | 388M/1.26G [00:14<00:32, 26.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\ntext_encoder/model.safetensors:  57%|████▌   | 388M/681M [00:15<00:11, 26.4MB/s]\u001b[A\n\n\n\n\nvision_encoder/model.safetensors:  32%|█▌   | 398M/1.26G [00:15<00:32, 26.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\ntext_encoder/model.safetensors:  59%|████▋   | 398M/681M [00:15<00:10, 26.4MB/s]\u001b[A\n\n\n\n\nvision_encoder/model.safetensors:  32%|█▌   | 409M/1.26G [00:15<00:32, 26.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\ntext_encoder/model.safetensors:  60%|████▊   | 409M/681M [00:16<00:10, 26.4MB/s]\u001b[A\n\n\n\n\nvision_encoder/model.safetensors:  33%|█▋   | 419M/1.26G [00:15<00:31, 26.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\nvision_encoder/model.safetensors:  34%|█▋   | 430M/1.26G [00:16<00:31, 26.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\ntext_encoder/model.safetensors:  62%|████▉   | 419M/681M [00:16<00:11, 23.7MB/s]\u001b[A\n\n\n\n\nvision_encoder/model.safetensors:  35%|█▋   | 440M/1.26G [00:16<00:30, 26.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\ntext_encoder/model.safetensors:  63%|█████   | 430M/681M [00:17<00:10, 24.4MB/s]\u001b[A\n\n\n\n\nvision_encoder/model.safetensors:  36%|█▊   | 451M/1.26G [00:17<00:30, 26.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\ntext_encoder/model.safetensors:  65%|█████▏  | 440M/681M [00:17<00:09, 24.9MB/s]\u001b[A\n\n\n\n\nvision_encoder/model.safetensors:  36%|█▊   | 461M/1.26G [00:17<00:30, 26.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\ntext_encoder/model.safetensors:  66%|█████▎  | 451M/681M [00:18<00:09, 25.3MB/s]\u001b[A\n\n\n\n\nvision_encoder/model.safetensors:  37%|█▊   | 472M/1.26G [00:17<00:29, 26.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\ntext_encoder/model.safetensors:  68%|█████▍  | 461M/681M [00:18<00:08, 25.6MB/s]\u001b[A\n\n\n\n\nvision_encoder/model.safetensors:  38%|█▉   | 482M/1.26G [00:18<00:29, 26.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\ntext_encoder/model.safetensors:  69%|█████▌  | 472M/681M [00:18<00:08, 25.8MB/s]\u001b[A\n\n\n\n\nvision_encoder/model.safetensors:  39%|█▉   | 493M/1.26G [00:18<00:28, 26.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\ntext_encoder/model.safetensors:  71%|█████▋  | 482M/681M [00:19<00:07, 26.0MB/s]\u001b[A\n\n\n\n\nvision_encoder/model.safetensors:  40%|█▉   | 503M/1.26G [00:19<00:28, 26.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\ntext_encoder/model.safetensors:  72%|█████▊  | 493M/681M [00:19<00:07, 26.1MB/s]\u001b[A\n\n\n\n\nvision_encoder/model.safetensors:  41%|██   | 514M/1.26G [00:19<00:28, 26.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\ntext_encoder/model.safetensors:  74%|█████▉  | 503M/681M [00:20<00:06, 26.2MB/s]\u001b[A\n\n\n\n\nvision_encoder/model.safetensors:  41%|██   | 524M/1.26G [00:19<00:27, 26.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\ntext_encoder/model.safetensors:  75%|██████  | 514M/681M [00:20<00:06, 25.4MB/s]\u001b[A\n\n\n\n\nvision_encoder/model.safetensors:  42%|██   | 535M/1.26G [00:20<00:27, 26.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\ntext_encoder/model.safetensors:  77%|██████▏ | 524M/681M [00:20<00:05, 26.5MB/s]\u001b[A\ntext_encoder/model.safetensors:  79%|██████▎ | 535M/681M [00:21<00:05, 26.5MB/s]\u001b[A\n\n\n\n\nvision_encoder/model.safetensors:  43%|██▏  | 545M/1.26G [00:20<00:30, 23.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\nvision_encoder/model.safetensors:  44%|██▏  | 556M/1.26G [00:21<00:25, 27.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\ntext_encoder/model.safetensors:  80%|██████▍ | 545M/681M [00:21<00:05, 26.4MB/s]\u001b[A\n\n\n\n\nvision_encoder/model.safetensors:  45%|██▏  | 566M/1.26G [00:21<00:25, 27.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\ntext_encoder/model.safetensors:  82%|██████▌ | 556M/681M [00:22<00:04, 26.4MB/s]\u001b[A\n\n\n\n\nvision_encoder/model.safetensors:  46%|██▎  | 577M/1.26G [00:21<00:25, 27.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\ntext_encoder/model.safetensors:  83%|██████▋ | 566M/681M [00:22<00:04, 26.4MB/s]\u001b[A\n\n\n\n\nvision_encoder/model.safetensors:  46%|██▎  | 587M/1.26G [00:22<00:25, 27.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\ntext_encoder/model.safetensors:  85%|██████▊ | 577M/681M [00:22<00:03, 26.4MB/s]\u001b[A\n\n\n\n\nvision_encoder/model.safetensors:  47%|██▎  | 598M/1.26G [00:22<00:24, 26.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\ntext_encoder/model.safetensors:  86%|██████▉ | 587M/681M [00:23<00:03, 26.4MB/s]\u001b[A\n\n\n\n\nvision_encoder/model.safetensors:  48%|██▍  | 608M/1.26G [00:22<00:24, 26.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\ntext_encoder/model.safetensors:  88%|███████ | 598M/681M [00:23<00:03, 26.4MB/s]\u001b[A\n\n\n\n\nvision_encoder/model.safetensors:  49%|██▍  | 619M/1.26G [00:23<00:24, 26.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\ntext_encoder/model.safetensors:  89%|███████▏| 608M/681M [00:24<00:02, 26.4MB/s]\u001b[A\n\n\n\n\nvision_encoder/model.safetensors:  50%|██▍  | 629M/1.26G [00:23<00:23, 26.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\ntext_encoder/model.safetensors:  91%|███████▎| 619M/681M [00:24<00:02, 26.4MB/s]\u001b[A\n\n\n\n\nvision_encoder/model.safetensors:  51%|██▌  | 640M/1.26G [00:24<00:23, 26.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\ntext_encoder/model.safetensors:  92%|███████▍| 629M/681M [00:24<00:01, 26.4MB/s]\u001b[A\n\n\n\n\nvision_encoder/model.safetensors:  51%|██▌  | 650M/1.26G [00:24<00:22, 26.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\ntext_encoder/model.safetensors:  94%|███████▌| 640M/681M [00:25<00:01, 26.4MB/s]\u001b[A\n\n\n\n\nvision_encoder/model.safetensors:  52%|██▌  | 661M/1.26G [00:24<00:22, 26.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\ntext_encoder/model.safetensors:  95%|███████▋| 650M/681M [00:25<00:01, 26.4MB/s]\u001b[A\n\n\n\n\nvision_encoder/model.safetensors:  53%|██▋  | 671M/1.26G [00:25<00:22, 26.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\ntext_encoder/model.safetensors:  97%|███████▊| 661M/681M [00:26<00:00, 26.3MB/s]\u001b[A\n\n\n\n\nvision_encoder/model.safetensors:  54%|██▋  | 682M/1.26G [00:25<00:24, 23.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\ntext_encoder/model.safetensors:  99%|███████▉| 671M/681M [00:26<00:00, 26.3MB/s]\u001b[A\n\n\n\n\nvision_encoder/model.safetensors:  55%|██▋  | 692M/1.26G [00:26<00:23, 24.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\ntext_encoder/model.safetensors: 100%|████████| 681M/681M [00:26<00:00, 25.4MB/s]\u001b[A\nFetching 16 files:  38%|█████████▍               | 6/16 [00:27<00:47,  4.78s/it]\n\n\n\n\nvision_encoder/model.safetensors:  56%|██▊  | 703M/1.26G [00:26<00:22, 25.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\nvision_encoder/model.safetensors:  56%|██▊  | 713M/1.26G [00:27<00:21, 25.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\nvision_encoder/model.safetensors:  57%|██▊  | 724M/1.26G [00:27<00:20, 25.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\nvision_encoder/model.safetensors:  58%|██▉  | 734M/1.26G [00:27<00:20, 26.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\nvision_encoder/model.safetensors:  59%|██▉  | 744M/1.26G [00:28<00:19, 26.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\nvision_encoder/model.safetensors:  60%|██▉  | 755M/1.26G [00:28<00:19, 26.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\nvision_encoder/model.safetensors:  61%|███  | 765M/1.26G [00:29<00:18, 26.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\nvision_encoder/model.safetensors:  61%|███  | 776M/1.26G [00:29<00:18, 26.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\nvision_encoder/model.safetensors:  62%|███  | 786M/1.26G [00:29<00:17, 26.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\nvision_encoder/model.safetensors:  63%|███▏ | 797M/1.26G [00:30<00:17, 26.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\nvision_encoder/model.safetensors:  64%|███▏ | 807M/1.26G [00:30<00:17, 26.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\nvision_encoder/model.safetensors:  65%|███▏ | 818M/1.26G [00:31<00:16, 26.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\nvision_encoder/model.safetensors:  66%|███▎ | 828M/1.26G [00:31<00:16, 26.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\nvision_encoder/model.safetensors:  66%|███▎ | 839M/1.26G [00:31<00:15, 26.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\nvision_encoder/model.safetensors:  67%|███▎ | 849M/1.26G [00:32<00:15, 26.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\nvision_encoder/model.safetensors:  68%|███▍ | 860M/1.26G [00:32<00:15, 26.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\nvision_encoder/model.safetensors:  69%|███▍ | 870M/1.26G [00:32<00:14, 26.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\nvision_encoder/model.safetensors:  70%|███▍ | 881M/1.26G [00:33<00:14, 26.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\nvision_encoder/model.safetensors:  71%|███▌ | 891M/1.26G [00:33<00:14, 26.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\nvision_encoder/model.safetensors:  71%|███▌ | 902M/1.26G [00:34<00:13, 26.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\nvision_encoder/model.safetensors:  72%|███▌ | 912M/1.26G [00:34<00:13, 26.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\nvision_encoder/model.safetensors:  73%|███▋ | 923M/1.26G [00:34<00:12, 26.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\nvision_encoder/model.safetensors:  74%|███▋ | 933M/1.26G [00:35<00:12, 26.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\nvision_encoder/model.safetensors:  75%|███▋ | 944M/1.26G [00:35<00:12, 26.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\nvision_encoder/model.safetensors:  75%|███▊ | 954M/1.26G [00:36<00:11, 26.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\nvision_encoder/model.safetensors:  76%|███▊ | 965M/1.26G [00:36<00:11, 26.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\nvision_encoder/model.safetensors:  77%|███▊ | 975M/1.26G [00:36<00:10, 26.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\nvision_encoder/model.safetensors:  78%|███▉ | 986M/1.26G [00:37<00:10, 26.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\nvision_encoder/model.safetensors:  79%|███▉ | 996M/1.26G [00:37<00:10, 26.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\nvision_encoder/model.safetensors:  80%|███▏| 1.01G/1.26G [00:38<00:09, 26.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\nvision_encoder/model.safetensors:  80%|███▏| 1.02G/1.26G [00:38<00:09, 26.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\nvision_encoder/model.safetensors:  81%|███▎| 1.03G/1.26G [00:38<00:08, 26.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\nvision_encoder/model.safetensors:  82%|███▎| 1.04G/1.26G [00:39<00:08, 26.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\nvision_encoder/model.safetensors:  83%|███▎| 1.05G/1.26G [00:39<00:08, 26.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\nvision_encoder/model.safetensors:  84%|███▎| 1.06G/1.26G [00:40<00:07, 26.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\nvision_encoder/model.safetensors:  85%|███▍| 1.07G/1.26G [00:40<00:07, 26.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\nvision_encoder/model.safetensors:  85%|███▍| 1.08G/1.26G [00:40<00:06, 26.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\nvision_encoder/model.safetensors:  86%|███▍| 1.09G/1.26G [00:41<00:06, 26.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\nvision_encoder/model.safetensors:  87%|███▍| 1.10G/1.26G [00:41<00:06, 26.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\nvision_encoder/model.safetensors:  88%|███▌| 1.11G/1.26G [00:42<00:05, 26.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\nvision_encoder/model.safetensors:  89%|███▌| 1.12G/1.26G [00:42<00:05, 26.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\nvision_encoder/model.safetensors:  90%|███▌| 1.13G/1.26G [00:42<00:04, 26.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\nvision_encoder/model.safetensors:  90%|███▌| 1.14G/1.26G [00:43<00:04, 26.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\nvision_encoder/model.safetensors:  91%|███▋| 1.15G/1.26G [00:43<00:04, 26.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\nvision_encoder/model.safetensors:  92%|███▋| 1.16G/1.26G [00:43<00:03, 26.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\nvision_encoder/model.safetensors:  93%|███▋| 1.17G/1.26G [00:44<00:03, 26.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\nvision_encoder/model.safetensors:  94%|███▋| 1.18G/1.26G [00:44<00:02, 26.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\nvision_encoder/model.safetensors:  95%|███▊| 1.20G/1.26G [00:45<00:02, 26.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\nvision_encoder/model.safetensors:  95%|███▊| 1.21G/1.26G [00:45<00:02, 26.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\nvision_encoder/model.safetensors:  96%|███▊| 1.22G/1.26G [00:45<00:01, 26.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\nvision_encoder/model.safetensors:  97%|███▉| 1.23G/1.26G [00:46<00:01, 26.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\nvision_encoder/model.safetensors:  98%|███▉| 1.24G/1.26G [00:46<00:01, 26.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\nvision_encoder/model.safetensors:  99%|███▉| 1.25G/1.26G [00:47<00:00, 26.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\nvision_encoder/model.safetensors: 100%|███▉| 1.26G/1.26G [00:47<00:00, 26.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\nvision_encoder/model.safetensors: 100%|████| 1.26G/1.26G [00:47<00:00, 26.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\nFetching 16 files: 100%|████████████████████████| 16/16 [00:48<00:00,  3.05s/it]\nLoading pipeline components...:  25%|███▎         | 2/8 [00:00<00:02,  2.88it/s]The config attributes {'dropout': 0.0, 'reverse_transformer_layers_per_block': None} were passed to UNet2DConditionModel, but are not expected and will be ignored. Please verify your config.json configuration file.\nLoading pipeline components...: 100%|█████████████| 8/8 [00:02<00:00,  2.97it/s]\nLoading custom white-background unet ...\ndiffusion_pytorch_model.bin: 100%|██████████| 1.73G/1.73G [00:03<00:00, 452MB/s]\nLoading reconstruction model ...\nconfig.json: 100%|█████████████████████████████| 454/454 [00:00<00:00, 2.55MB/s]\npytorch_model.bin: 100%|█████████████████████| 343M/343M [00:08<00:00, 39.7MB/s]\n/opt/conda/lib/python3.10/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n  return self.fget.__get__(instance, owner)()\nSome weights of ViTModel were not initialized from the model checkpoint at facebook/dino-vitb16 and are newly initialized: ['encoder.layer.0.adaLN_modulation.1.bias', 'encoder.layer.0.adaLN_modulation.1.weight', 'encoder.layer.1.adaLN_modulation.1.bias', 'encoder.layer.1.adaLN_modulation.1.weight', 'encoder.layer.10.adaLN_modulation.1.bias', 'encoder.layer.10.adaLN_modulation.1.weight', 'encoder.layer.11.adaLN_modulation.1.bias', 'encoder.layer.11.adaLN_modulation.1.weight', 'encoder.layer.2.adaLN_modulation.1.bias', 'encoder.layer.2.adaLN_modulation.1.weight', 'encoder.layer.3.adaLN_modulation.1.bias', 'encoder.layer.3.adaLN_modulation.1.weight', 'encoder.layer.4.adaLN_modulation.1.bias', 'encoder.layer.4.adaLN_modulation.1.weight', 'encoder.layer.5.adaLN_modulation.1.bias', 'encoder.layer.5.adaLN_modulation.1.weight', 'encoder.layer.6.adaLN_modulation.1.bias', 'encoder.layer.6.adaLN_modulation.1.weight', 'encoder.layer.7.adaLN_modulation.1.bias', 'encoder.layer.7.adaLN_modulation.1.weight', 'encoder.layer.8.adaLN_modulation.1.bias', 'encoder.layer.8.adaLN_modulation.1.weight', 'encoder.layer.9.adaLN_modulation.1.bias', 'encoder.layer.9.adaLN_modulation.1.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\npreprocessor_config.json: 100%|████████████████| 244/244 [00:00<00:00, 1.29MB/s]\ninstant_mesh_base.ckpt: 100%|███████████████| 1.25G/1.25G [00:02<00:00, 458MB/s]\nTotal number of input images: 1\nDownloading data from 'https://github.com/danielgatis/rembg/releases/download/v0.0.0/u2net.onnx' to file '/root/.u2net/u2net.onnx'.\n100%|████████████████████████████████████████| 176M/176M [00:00<00:00, 746GB/s]\n[1/1] Imagining pikachu ...\n100%|███████████████████████████████████████████| 75/75 [01:18<00:00,  1.05s/it]\nImage saved to outputs/instant-mesh-base/images/pikachu.png\n[1/1] Creating pikachu ...\nMesh saved to outputs/instant-mesh-base/meshes/pikachu.obj\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"!python run.py configs/instant-mesh-base.yaml examples/plant.jpg --export_texmap --output_path /kaggle/working/","metadata":{"execution":{"iopub.status.busy":"2024-05-30T18:21:54.277154Z","iopub.execute_input":"2024-05-30T18:21:54.278227Z","iopub.status.idle":"2024-05-30T18:24:06.763230Z","shell.execute_reply.started":"2024-05-30T18:21:54.278189Z","shell.execute_reply":"2024-05-30T18:24:06.762184Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"2024-05-30 18:22:05.133766: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-05-30 18:22:05.133870: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-05-30 18:22:05.135460: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\nLoading diffusion model ...\nLoading pipeline components...:  62%|████████▏    | 5/8 [00:01<00:00,  4.95it/s]The config attributes {'dropout': 0.0, 'reverse_transformer_layers_per_block': None} were passed to UNet2DConditionModel, but are not expected and will be ignored. Please verify your config.json configuration file.\nLoading pipeline components...: 100%|█████████████| 8/8 [00:05<00:00,  1.42it/s]\nLoading custom white-background unet ...\nLoading reconstruction model ...\n/opt/conda/lib/python3.10/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n  return self.fget.__get__(instance, owner)()\nSome weights of ViTModel were not initialized from the model checkpoint at facebook/dino-vitb16 and are newly initialized: ['encoder.layer.0.adaLN_modulation.1.bias', 'encoder.layer.0.adaLN_modulation.1.weight', 'encoder.layer.1.adaLN_modulation.1.bias', 'encoder.layer.1.adaLN_modulation.1.weight', 'encoder.layer.10.adaLN_modulation.1.bias', 'encoder.layer.10.adaLN_modulation.1.weight', 'encoder.layer.11.adaLN_modulation.1.bias', 'encoder.layer.11.adaLN_modulation.1.weight', 'encoder.layer.2.adaLN_modulation.1.bias', 'encoder.layer.2.adaLN_modulation.1.weight', 'encoder.layer.3.adaLN_modulation.1.bias', 'encoder.layer.3.adaLN_modulation.1.weight', 'encoder.layer.4.adaLN_modulation.1.bias', 'encoder.layer.4.adaLN_modulation.1.weight', 'encoder.layer.5.adaLN_modulation.1.bias', 'encoder.layer.5.adaLN_modulation.1.weight', 'encoder.layer.6.adaLN_modulation.1.bias', 'encoder.layer.6.adaLN_modulation.1.weight', 'encoder.layer.7.adaLN_modulation.1.bias', 'encoder.layer.7.adaLN_modulation.1.weight', 'encoder.layer.8.adaLN_modulation.1.bias', 'encoder.layer.8.adaLN_modulation.1.weight', 'encoder.layer.9.adaLN_modulation.1.bias', 'encoder.layer.9.adaLN_modulation.1.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\nTotal number of input images: 1\n[1/1] Imagining plant ...\n100%|███████████████████████████████████████████| 75/75 [01:18<00:00,  1.05s/it]\nImage saved to /kaggle/working/instant-mesh-base/images/plant.png\n[1/1] Creating plant ...\nMesh saved to /kaggle/working/instant-mesh-base/meshes/plant.obj\n\u001b[0m","output_type":"stream"}]}]}